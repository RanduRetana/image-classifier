# image-classifier
# Clasificaci√≥n de Im√°genes de Ronaldo, Maria Sharapova y Kobe Bryant

## Descripci√≥n del Proyecto

Este proyecto tiene como objetivo entrenar un modelo de deep learning capaz de clasificar im√°genes de tres personas: **Cristiano Ronaldo**, **Maria Sharapova** y **Kobe Bryant**. A trav√©s de redes neuronales convolucionales (CNN), buscamos que el modelo identifique a cada individuo a pesar de variaciones como ropa, fondo y pose.

Durante el desarrollo, se identificaron **problemas de sesgo visual** en el dataset inicial, lo que motiv√≥ modificaciones en la base de datos y el modelo utilizado.

---

## Descripci√≥n del Dataset

La carpeta `data_images/` contiene tres subcarpetas:

- `Ronaldo/`
- `Maria Sharapova/`
- `Kobe Bryant/`

Inicialmente, las im√°genes de Ronaldo ten√≠an un sesgo importante: **todas mostraban al jugador con uniforme rojo**. Esto provocaba que el modelo confundiera a Sharapova o Kobe cuando aparec√≠an con ropa de ese mismo color. Para solucionar esto:

- Se a√±adieron im√°genes de Ronaldo **con ropa de distintos colores**.
- Se incorporaron **m√°s im√°genes de los tres sujetos** para mejorar la diversidad y cantidad de datos por clase.

---

## Modelo Utilizado


### Modelo Inicial

Se comenz√≥ con una CNN simple con tres capas convolucionales y una capa densa final:
Input: Imagen RGB de 128x128 ‚Üì Conv2D (32) ‚Üí ReLU ‚Üì Conv2D (64) ‚Üí ReLU ‚Üì Conv2D (128) ‚Üí ReLU ‚Üì Flatten ‚Üì Dense (128) ‚Üí ReLU ‚Üì Dense (3) ‚Üí Softmax


Este modelo sirvi√≥ como primera aproximaci√≥n, pero presentaba limitaciones en capacidad de generalizaci√≥n y requer√≠a muchas √©pocas para converger. Adem√°s, no inclu√≠a t√©cnicas de regularizaci√≥n como MaxPooling o Dropout.

---

### üöÄ Modelo Mejorado (Inspirado en AlexNet)

Basado en el an√°lisis del paper ["ImageNet Classification with Deep Convolutional Neural Networks" (Krizhevsky et al., 2012)](https://papers.nips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf), se redise√±√≥ el modelo incorporando elementos clave de **AlexNet**, como MaxPooling y Dropout.

```python
model = Sequential()

model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(3, activation='softmax'))
```
Este redise√±o mejor√≥ significativamente la precisi√≥n y redujo la cantidad de √©pocas necesarias para converger. En solo 40 √©pocas, el nuevo modelo logr√≥ un rendimiento mucho mayor que el modelo original.

El art√≠culo de Krizhevsky et al. sirvi√≥ como justificaci√≥n te√≥rica para el uso de arquitecturas profundas, ReLU como funci√≥n de activaci√≥n, y t√©cnicas de regularizaci√≥n como Dropout y MaxPooling. La arquitectura AlexNet demostr√≥ ser altamente efectiva en clasificaci√≥n de im√°genes a gran escala, validando nuestro enfoque.

---

### Generaci√≥n de Datos de Entrenamiento y Testeo
Se utilizaron generadores de im√°genes con ImageDataGenerator de Keras para:

- Redimensionar im√°genes a 128x128 px

- Normalizar valores de p√≠xeles

- Aplicar data augmentation (giro, zoom, traslaci√≥n) para aumentar la robustez del modelo

- Los datos fueron separados en 80% entrenamiento y 20% testeo.

---

### M√©tricas de Evaluaci√≥n
- Accuracy (precisi√≥n global)

- Matriz de Confusi√≥n

- [Futuro] Se planea incorporar F1-score, Precision y Recall para an√°lisis m√°s profundo del rendimiento, especialmente si se detectan desbalances.

---

### Conclusiones
- El dataset inicial presentaba sesgos importantes que fueron corregidos agregando im√°genes m√°s variadas.

- El modelo inicial fue √∫til como prueba de concepto, pero fue superado ampliamente por la versi√≥n inspirada en AlexNet, la cual logr√≥ mejor rendimiento con menos entrenamiento.

- El art√≠culo de Krizhevsky et al. sirvi√≥ como inspiraci√≥n y respaldo para mejorar la arquitectura y demostrar la eficacia de redes profundas en clasificaci√≥n visual.



